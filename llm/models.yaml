defaults: { temperature: 0.2, max_tokens: 1200, timeout: 60 }

providers:
  groq:
    base_url: https://api.groq.com/openai/v1
    api_key: "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"
    models:
      - model_id: llama-3.1-8b-instant
        cost_per_million: { input: 0.05, output: 0.08 }  # Groq pricing
      - model_id: llama-3.3-70b-versatile
        cost_per_million: { input: 0.59, output: 0.79 }  # Groq pricing
      - model_id: meta-llama/llama-4-maverick-17b-128e-instruct
        cost_per_million: { input: 0.20, output: 0.60 }  # Groq pricing
      - model_id: meta-llama/llama-4-scout-17b-16e-instruct
        cost_per_million: { input: 0.11, output: 0.34 }  # Groq pricing
      - model_id: moonshotai/kimi-k2-instruct
        # Groq lists the model; pricing depends on host; leave blank or set what you actually pay

  deepseek:
    base_url: https://api.deepseek.com/v1
    api_key: "sk-3f6fb6901cd04b238c9c974b1e067311"
    models:
      - model_id: deepseek-chat            # V3.1 under the hood now (non-thinking)
        cost_per_million: {input: 0.27, output: 1.10}

  google:
    base_url: "https://generativelanguage.googleapis.com/v1beta/openai/"
    api_key: "AIzaSyCTCNJPrbibee77gt1IFnnFFWbUd2v3g-A"
    models:
      - model_id: gemini-2.5-flash
        cost_per_million: { input: 0.30, output: 2.50 }
      - model_id: gemini-2.5-flash-lite
        cost_per_million: { input: 0.10, output: 0.40 }

  openai:
    base_url: "https://api.openai.com/v1"
    api_key: "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"
    models:
      - model_id: "gpt-5-mini"
        cost_per_million: { input: 0.30, output: 1.20 }
      - model_id: "gpt-4o-mini"
        cost_per_million: { input: 0.15, output: 0.60 }